name: Auto YouTube Short

on:
  workflow_dispatch:

jobs:
  make-video:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg python3 python3-venv jq
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install TTS

      - name: Pick category
        id: pick_category
        run: |
          CATEGORY=$(shuf -e horror crime mystery | head -n1)
          echo "CATEGORY=$CATEGORY" >> "$GITHUB_ENV"

      # (Optional) still fetch Wikipedia text, but we don't inject it into JSON yet
      - name: Fetch Wikipedia source
        id: wiki
        run: |
          if [ "${CATEGORY}" = "horror" ]; then
            TOPIC="List_of_reportedly_haunted_locations_in_the_United_States"
          elif [ "${CATEGORY}" = "crime" ]; then
            TOPIC="List_of_unsolved_murder_cases_in_the_United_States"
          else
            TOPIC="List_of_missing_persons_cases"
          fi

          TEXT=$(curl -s "https://en.wikipedia.org/w/api.php?action=query&prop=extracts&explaintext=1&titles=${TOPIC}&format=json" \
            | jq -r '.query.pages[]?.extract' | head -c 8000)

          {
            echo "source_text<<EOF"
            echo "$TEXT"
            echo "EOF"
          } >> "$GITHUB_ENV"

      - name: Generate metadata & script with Groq
        id: script
        env:
          GROQ_KEY: ${{ secrets.GROQ_KEY }}
        run: |
          # Build JSON payload safely (no crazy quoting)
          cat << EOF > payload.json
          {
            "model": "llama3-8b-8192",
            "response_format": {"type": "json_object"},
            "messages": [
              {
                "role": "system",
                "content": "You write short, factual YouTube horror/crime/mystery scripts. Respond ONLY as compact JSON: {\"title\": string, \"description\": string, \"tags\": [string], \"script\": string}."
              },
              {
                "role": "user",
                "content": "Write a 25-35 second YouTube Shorts script in American English about a ${CATEGORY} story inspired by real Wikipedia-like facts. Make it punchy but factual. Then provide a title, a 1-2 sentence description, and 5-10 tags as a JSON array of strings."
              }
            ]
          }
          EOF

          JSON_OUT=$(curl -s https://api.groq.com/openai/v1/chat/completions \
            -H "Authorization: Bearer ${GROQ_KEY}" \
            -H "Content-Type: application/json" \
            -d @payload.json)

          echo "$JSON_OUT" > groq_raw.json
          CONTENT=$(echo "$JSON_OUT" | jq -r '.choices[0].message.content')

          TITLE=$(echo "$CONTENT" | jq -r '.title')
          DESCRIPTION=$(echo "$CONTENT" | jq -r '.description')
          TAGS=$(echo "$CONTENT" | jq -r '.tags | join(",")')
          SCRIPT=$(echo "$CONTENT" | jq -r '.script')

          {
            echo "TITLE=$TITLE"
            echo "DESCRIPTION=$DESCRIPTION"
            echo "TAGS=$TAGS"
            echo "script<<EOF"
            echo "$SCRIPT"
            echo "EOF"
          } >> "$GITHUB_ENV"

      - name: Save script to file (for Python & XTTS)
        run: |
          cat << 'SCRIPT' > script.txt
${{ env.script }}
SCRIPT

      - name: Build Subtitles
        run: |
          python3 << 'EOF'
with open("script.txt", "r", encoding="utf-8") as f:
    script = f.read()

lines = [l.strip() for l in script.split("\n") if l.strip()]

def tc(ms):
    h = ms//3600000; ms%=3600000
    m = ms//60000; ms%=60000
    s = ms//1000; r = ms%1000
    return f"{h:02}:{m:02}:{s:02},{r:03}"

time = 0
srt_lines = []
index = 1

for line in lines:
    start = time
    end = time + 3000
    srt_lines.append(str(index))
    srt_lines.append(f"{tc(start)} --> {tc(end)}")
    srt_lines.append(line)
    srt_lines.append("")
    index += 1
    time = end

with open("subtitles.srt", "w", encoding="utf-8") as f:
    f.write("\n".join(srt_lines))
EOF

      - name: Fetch Pexels Video
        env:
          PEXELS_KEY: ${{ secrets.PEXELS_KEY }}
        run: |
          VIDEO_URL=$(curl -s -H "Authorization: ${PEXELS_KEY}" \
            "https://api.pexels.com/videos/search?query=${CATEGORY}&per_page=1" \
            | jq -r '.videos[0].video_files[0].link')

          echo "Video URL: $VIDEO_URL"
          curl -L "$VIDEO_URL" -o video.mp4

      - name: Generate Voice (XTTS)
        run: |
          source venv/bin/activate
          python3 << 'EOF'
from TTS.api import TTS

with open("script.txt", "r", encoding="utf-8") as f:
    script = f.read()

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
tts.tts_to_file(
    text=script,
    file_path="tts-audio.wav",
    speaker_wav="voices/aman.wav",
    language="en"
)
EOF

      - name: Render Final Video
        run: |
          ffmpeg -y \
            -i video.mp4 \
            -i tts-audio.wav \
            -vf "scale=1080:-2,crop=1080:1920,subtitles=subtitles.srt" \
            -map 0:v -map 1:a \
            -shortest \
            -c:v libx264 -preset veryfast -crf 23 \
            -c:a aac \
            output.mp4

      - name: Generate Thumbnail
        run: |
          ffmpeg -y \
            -ss 00:00:02 -i output.mp4 -vframes 1 \
            -vf "scale=1280:-2,drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf:text='${TITLE}':fontcolor=white:fontsize=48:box=1:boxcolor=black@0.6:boxborderw=20:x=(w-text_w)/2:y=h*0.15" \
            thumbnail.jpg

              - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: youtube-short
          path: |
            output.mp4
            thumbnail.jpg
            subtitles.srt
            groq_raw.json
            script.txt

    
